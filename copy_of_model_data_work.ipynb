{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display existing tables\n",
    "dbutils.fs.ls(\"/FileStore/tables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bb0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in parquet table of the Open Library author data dump and display\n",
    "file_location = '/FileStore/tables/author_key_df_snappy.parquet'\n",
    "ol_authors = spark.read.parquet(file_location)\n",
    "display(ol_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in authors.csv data from previous projects on NYT bestsellers, display.\n",
    "file_location = '/FileStore/tables/authors.csv'\n",
    "nyt_authors_df = spark.read.csv(file_location, inferSchema=True, header=False)\n",
    "nyt_authors_df = nyt_authors_df.withColumnRenamed(\"_c0\", \"author_id\")\n",
    "nyt_authors_df = nyt_authors_df.withColumnRenamed(\"_c1\", \"author_name\")\n",
    "display(nyt_authors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary functions\n",
    "from pyspark.sql.functions import col, when, split, length, substring, expr, regexp_extract, upper, size, lower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ea294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create joined table between OL authors and the NYT bestseller authors\n",
    "nyt_author_key = ol_authors.join(nyt_authors_df, on='author_name', how='inner')\n",
    "\n",
    "# Choose only OL key and name\n",
    "nyt_ol_joined_inner = nyt_author_key.select('author_key', 'author_name')\n",
    "\n",
    "# Add the column from the NYT bestseller list to indicate ID from previous projects\n",
    "nyt_author_add_id = nyt_ol_joined_inner.join(nyt_authors_df, on='author_name', how='inner')\n",
    "\n",
    "# Select the final desired columns\n",
    "nyt_author_key_id = nyt_author_add_id.select('author_key', 'author_name', 'author_id')\n",
    "nyt_author_key_id = nyt_author_key_id.orderBy(col('author_id'))\n",
    "\n",
    "display(nyt_author_key_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8770883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left join to combine OL and bestsellers based on \"author_id\" and \"author_name\"\n",
    "joined_df = ol_authors.join(nyt_author_key_id, on=[\"author_name\",\"author_key\"], how=\"left\")\n",
    "\n",
    "# Add a new column \"present_in_nyt\" to indicate if the author is also a bestseller\n",
    "joined_df = joined_df.withColumn(\"nyt_bestseller\", when(col(\"author_id\").isNotNull(), 1).otherwise(0))\n",
    "\n",
    "# Select the desired columns: author_id, author_name, and present_in_nyt\n",
    "authors_for_model_df = joined_df.select(\"author_key\", \"author_name\", \"nyt_bestseller\")\n",
    "\n",
    "# Show the result DataFrame\n",
    "display(authors_for_model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb7865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many are on the Bestseller list (\"1\") and how many are not (\"0\")\n",
    "unique_values_counts = authors_for_model_df.groupBy(\"nyt_bestseller\").count()\n",
    "\n",
    "display(unique_values_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f9b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, split, length, substring, expr, regexp_extract\n",
    "\n",
    "# Use regexp_extract to pull the last word from the \"author_name\" column\n",
    "result_df = authors_for_model_df.withColumn(\"last_name\", regexp_extract(col(\"author_name\"), r\"\\b(\\w+)\\s*$\", 1))\n",
    "\n",
    "# Filter out the empties and spaces from the \"last_name\" column\n",
    "result_df = result_df.withColumn(\"last_name\", expr(\"CASE WHEN trim(last_name) = '' THEN NULL ELSE last_name END\"))\n",
    "\n",
    "# Get the first letter of the last name using the substring function\n",
    "authors_for_model_df = result_df.withColumn(\"last_initial\", substring(col(\"last_name\"), 1, 1))\n",
    "\n",
    "\n",
    "display(authors_for_model_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddce4c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the counts of authors per first letter of last name.\n",
    "alphabetical_last_name_counts = authors_for_model_df.groupBy(\"last_initial\").count()\n",
    "\n",
    "# Order it alphabetically by first letter of last name\n",
    "alphabetical_last_name_counts = alphabetical_last_name_counts.orderBy(\"last_initial\")\n",
    "\n",
    "\n",
    "display(alphabetical_last_name_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec26ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a temporary view\n",
    "alphabetical_last_name_counts.createOrReplaceTempView(\"last_initial_counts\")\n",
    "\n",
    "numeric_last_initial_total = spark.sql(\"\"\"\n",
    "    SELECT SUM(count) AS numeric_last_initial_count\n",
    "    FROM last_initial_counts\n",
    "    WHERE last_initial IN (\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\")\n",
    "    \"\"\").collect()\n",
    "                                                    \n",
    "# Extract the count of numeric values from the result\n",
    "numeric_last_initial_count = numeric_last_initial_total[0][\"numeric_last_initial_count\"]\n",
    "\n",
    "\n",
    "# Use Spark SQL query to count the occurrences of null values in \"last_initial\" column\n",
    "null_last_initial_result = spark.sql(\"\"\"\n",
    "    SELECT count AS null_last_initial_count\n",
    "    FROM last_initial_counts\n",
    "    WHERE last_initial IS NULL\n",
    "\"\"\").collect()\n",
    "\n",
    "# Extract the count of null values from the result\n",
    "null_last_initial_count = null_last_initial_result[0][\"null_last_initial_count\"]\n",
    "\n",
    "# Assign a variable to total rows for calculations\n",
    "total_authors = authors_for_model_df.count()\n",
    "\n",
    "# Calculate percentage of null and numeric for deletion consideration\n",
    "total_special_character_initial = numeric_last_initial_count + null_last_initial_count\n",
    "percentage_of_authors = (total_special_character_initial/total_authors) * 100\n",
    "\n",
    "# Display the counts\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Count of Numeric Last Initials: \", numeric_last_initial_count)\n",
    "print(\"Count of Null Last Initials: \", null_last_initial_count)\n",
    "print(\"Null and Numeric Last Initials Represent \",percentage_of_authors,\"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2458d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with \"null\" or numbers in the \"last_initial\" column\n",
    "author_model_data = authors_for_model_df.filter(\n",
    "    col(\"last_initial\").isNotNull()  \n",
    "    & ~col(\"last_initial\").rlike(r\"^\\d\")  # Remove rows starting with numbers\n",
    ")\n",
    "\n",
    "# Replace lower-case letters with their upper-case counterparts in the \"last_name_initial\" column\n",
    "author_model_data = author_model_data.withColumn(\"last_initial\", upper(col(\"last_initial\")))\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "author_model_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ebacaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the counts of authors per first letter of last name.\n",
    "last_initial_counts = author_model_data.groupBy(\"last_initial\").count()\n",
    "\n",
    "# Order it alphabetically by first letter of last name\n",
    "last_initial_counts = last_initial_counts.orderBy(\"last_initial\")\n",
    "\n",
    "\n",
    "display(last_initial_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8302a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in parquet table of the Open Library author data dump and display\n",
    "file_location = '/FileStore/tables/works_key_snappy.parquet'\n",
    "ol_works = spark.read.parquet(file_location)\n",
    "display(ol_works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cea9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a temporary view\n",
    "ol_works.createOrReplaceTempView(\"works\")\n",
    "\n",
    "\n",
    "# Use Spark SQL query to count the occurrences of null values in \"last_initial\" column\n",
    "null_author_result = spark.sql(\"\"\"\n",
    "    SELECT count(*) AS null_author_count\n",
    "    FROM works\n",
    "    WHERE author_key IS NULL\n",
    "\"\"\").collect()\n",
    "\n",
    "# Fetch the count value from the result\n",
    "null_author_count = null_author_result[0][\"null_author_count\"]\n",
    "print(\"The number of works with a null in the author_key value is:\", null_author_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c512fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building dense data\n",
    "works_data = ol_works.dropna(subset=[\"author_key\"])\n",
    "\n",
    "display(works_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f660bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_data.createOrReplaceTempView(\"works_data\")\n",
    "author_model_data.createOrReplaceTempView(\"author_data\")\n",
    "\n",
    "# Create a new DataFrame by joining 'df1' and 'df2' on \"author_key\"\n",
    "works_model = spark.sql(\"\"\"\n",
    "    SELECT works_data.work_key, works_data.title, author_model_data.author_key, author_model_data.author_name,\n",
    "           author_model_data.nyt_bestseller, author_model_data.last_initial\n",
    "    FROM works_data works_data\n",
    "    INNER JOIN author_data author_model_data ON works_data.author_key = author_model_data.author_key\n",
    "\"\"\")\n",
    "\n",
    "# Show the new DataFrame\n",
    "works_model.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_model = works_model.withColumnRenamed(\"nyt_bestseller\", \"nyt_best_author\")\n",
    "works_model = works_model.withColumnRenamed(\"last_initial\", \"author_last_initial\")\n",
    "\n",
    "display(works_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_model.createOrReplaceTempView(\"works_model\")\n",
    "\n",
    "# Add a new column \"title_word_count\" that shows the number of words in the \"title\" column\n",
    "works_model_data = works_model.withColumn(\"title_word_count\", size(split(col(\"title\"), \" \")))\n",
    "\n",
    "# Show the DataFrame with the new column \"title_word_count\"\n",
    "display(works_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f2b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dbfs_output_path = \"/FileStore/tables/model_test_works_authors\"\n",
    "\n",
    "# works_model_data.write.parquet(dbfs_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300a7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dbfs_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in authors.csv data from previous projects on NYT bestsellers, display.\n",
    "file_location = '/FileStore/tables/books.csv'\n",
    "nyt_books_df = spark.read.csv(file_location, inferSchema=True, header=False)\n",
    "# nyt_authors_df = nyt_authors_df.withColumnRenamed(\"_c0\", \"author_id\")\n",
    "# nyt_authors_df = nyt_authors_df.withColumnRenamed(\"_c1\", \"author_name\")\n",
    "display(nyt_books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53dd1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Register the DataFrames as temporary tables\n",
    "works_model.createOrReplaceTempView(\"table1\")\n",
    "nyt_books_df.createOrReplaceTempView(\"table2\")\n",
    "\n",
    "# Convert both \"title\" columns to lowercase before the join\n",
    "works_model_lower = works_model.withColumn(\"title_lower\", lower(col(\"title\")))\n",
    "nyt_books_df_lower = nyt_books_df.withColumn(\"title_lower\", lower(col(\"_c1\")))\n",
    "\n",
    "# Perform the join on the lowercase \"title_lower\" column\n",
    "model_data = works_model_lower.join(nyt_books_df_lower, [\"title_lower\"], \"inner\").drop(\"title_lower\")\n",
    "\n",
    "# Show the merged DataFrame with the common \"title\" column\n",
    "display(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73999978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates\n",
    "model_data = model_data.dropDuplicates([\"work_key\"])\n",
    "display(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3365916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left join to combine OL and bestsellers based on \"author_id\" and \"author_name\"\n",
    "attempt = works_model.join(model_data, on=[\"work_key\",\"title\",\"author_key\",\"author_name\",\"nyt_best_author\", \"author_last_initial\"], how=\"left\")\n",
    "\n",
    "# Add a new column \"work_on_nyt\" to indicate if the work is also a bestseller\n",
    "attempt = attempt.withColumn(\"work_on_nyt\", when(col(\"_c1\").isNotNull(), 1).otherwise(0))\n",
    "\n",
    "# Select the desired columns: author_id, author_name, and present_in_nyt\n",
    "attempt_model = attempt.select(\"work_key\", \"title\", \"author_key\", \"author_name\", \"nyt_best_author\",\"author_last_initial\",\"work_on_nyt\")\n",
    "\n",
    "# Show the result DataFrame\n",
    "display(attempt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5400f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a temporary view\n",
    "attempt_model.createOrReplaceTempView(\"attempt_model\")\n",
    "\n",
    "works_on_nyt_total = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS works_on_nyt_count\n",
    "    FROM attempt_model\n",
    "    WHERE work_on_nyt == 1\n",
    "    \"\"\").collect()\n",
    "                                                    \n",
    "# Extract the count of numeric values from the result\n",
    "works_on_nyt_count = works_on_nyt_total[0][\"works_on_nyt_count\"]\n",
    "\n",
    "works_NOT_on_nyt_total = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS works_NOT_on_nyt_count\n",
    "    FROM attempt_model\n",
    "    WHERE work_on_nyt == 0\n",
    "    \"\"\").collect()\n",
    "                                                    \n",
    "# Extract the count of numeric values from the result\n",
    "works_NOT_on_nyt_count = works_NOT_on_nyt_total[0][\"works_NOT_on_nyt_count\"]\n",
    "\n",
    "# Assign a variable to total rows for calculations\n",
    "total_works = attempt_model.count()\n",
    "\n",
    "\n",
    "# Display the counts\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Count of Works on a NYT Bestseller List: \", works_on_nyt_count)\n",
    "print(\"Count of Works NOT on a NYT Bestseller List: \", works_NOT_on_nyt_count)\n",
    "print(\"Total works represented \", total_works)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a09a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260efe0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0360a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610671ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d542ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
